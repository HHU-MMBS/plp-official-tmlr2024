{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5584286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/plp-official-tmlr2024/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb06cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "from utils import fix_random_seeds\n",
    "from torch.utils.data import Subset, DataLoader,Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics.functional import image_gradients\n",
    "\n",
    "from eval_utils import roc_auc_score, OOD_classifier_knn\n",
    "from loaders import get_dataset\n",
    "from model_builders.model_utils import split_normalization\n",
    "from model_builders import *\n",
    "\n",
    "out_dir = Path('./experiments/adversarial-dataset')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "fix_random_seeds(0)\n",
    "available_models('openclip*')\n",
    "model, preprocess = load_backbone('openclip_ViT-bigG-14/laion2b')\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.cuda().eval()\n",
    "pre, norm = split_normalization(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "smooth_lambda = 5e3\n",
    "steps= 250\n",
    "\n",
    "cifar100_train = get_dataset('CIFAR100', transform=pre, train=True)\n",
    "train_idx = np.random.choice(len(cifar100_train), N)\n",
    "cifar100_train = Subset(cifar100_train, train_idx)\n",
    "\n",
    "cifar100_test = get_dataset('CIFAR100', transform=pre, train=False)\n",
    "cifar100_test = Subset(cifar100_test, np.random.choice(len(cifar100_test), N))\n",
    "\n",
    "cifar10 = get_dataset('CIFAR10', transform=pre, train=False)\n",
    "cifar10 = Subset(cifar10, np.random.choice(len(cifar10), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adv(orig_dset, target_dset, lr=1e-3, steps=200, eps=1e-3, smooth_lambda=1e3, bs=16):\n",
    "    perts = []\n",
    "    ys = []\n",
    "    y_embed = []\n",
    "    adv_embed = []\n",
    "\n",
    "    loader_x = DataLoader(target_dset, batch_size=bs, pin_memory=True, shuffle=False)\n",
    "    loader_y = DataLoader(orig_dset, batch_size=bs, pin_memory=True, shuffle=False)\n",
    "    for (x,_), (y,_) in tqdm(zip(loader_x, loader_y), total=len(loader_y)):\n",
    "        ys.append(y)\n",
    "        with torch.no_grad():\n",
    "            target = model(norm(x.cuda()))\n",
    "        y = y.cuda()\n",
    "        pert = torch.randn_like(y, requires_grad=True)\n",
    "        pert.data *= eps\n",
    "        pert.data.clamp_(-y, 1-y)\n",
    "        opt = torch.optim.Adam([pert], lr=lr)\n",
    "        with tqdm(range(steps), leave=False) as pbar:\n",
    "            for _ in pbar:\n",
    "                pert.grad = None\n",
    "                out = model(norm(y + pert))\n",
    "                dy, dx = image_gradients(pert)\n",
    "                smooth_loss = dy.square().mean() + dx.square().mean()\n",
    "                sim = F.cosine_similarity(out, target).mean()\n",
    "                loss = -sim + smooth_lambda * smooth_loss\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                \n",
    "                pert.data.clamp_(-y, 1-y)\n",
    "                pbar.set_postfix(sim=sim.item(), norm=pert.square().mean().item())\n",
    "        perts.append(pert.detach().cpu())\n",
    "        with torch.no_grad():\n",
    "            y_embed.append(model(norm(y)).cpu())\n",
    "            adv_embed.append(model(norm(y + pert)).cpu())\n",
    "\n",
    "    ys = torch.cat(ys)\n",
    "    perts = torch.cat(perts)\n",
    "    y_embed = torch.cat(y_embed)\n",
    "    adv_embed = torch.cat(adv_embed)\n",
    "    return dict(\n",
    "        orig=ys,\n",
    "        orig_embed=y_embed,\n",
    "        perturbations=perts,\n",
    "        adv_embed=adv_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_smooth = compute_adv(cifar10, cifar100_train, bs=16, smooth_lambda=smooth_lambda, steps=steps)\n",
    "result_patchy = compute_adv(cifar10, cifar100_train, bs=16, smooth_lambda=0, steps=steps)\n",
    "torch.save(result_smooth, out_dir / 'perts_smooth.pt')\n",
    "torch.save(result_patchy, out_dir / 'result_patchy.pt')\n",
    "torch.save(train_idx, out_dir / 'target_idx.pt')\n",
    "targets, _ = next(iter(DataLoader(cifar100_train, N)))\n",
    "torch.save(targets, out_dir / 'targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a121f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed = []\n",
    "loader = DataLoader(cifar100_test, batch_size=32, pin_memory=True)\n",
    "with torch.no_grad():\n",
    "    for x, _ in tqdm(loader):\n",
    "        x = x.cuda()\n",
    "        x_embed.append(model(norm(x)).cpu())\n",
    "x_embed = torch.cat(x_embed)\n",
    "x_train_embed = load_embeds(arch='openclip_ViT-bigG-14/laion2b', dataset='CIFAR100', test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bbb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_auroc(result, x_embed, train_idx):\n",
    "    x_train_embed = load_embeds(arch='openclip_ViT-bigG-14/laion2b', dataset='CIFAR100', test=False)\n",
    "    y_embed = result['orig_embed']\n",
    "    adv_embed = result['adv_embed']\n",
    "    \n",
    "    bs=8\n",
    "    scores_in = OOD_classifier_knn(x_train_embed, x_embed, k=1, metric='cos-sim', args=None, num_chunks=bs)\n",
    "    scores_out = OOD_classifier_knn(x_train_embed, y_embed, k=1, metric='cos-sim', args=None, num_chunks=bs)\n",
    "    scores_adv = OOD_classifier_knn(x_train_embed, adv_embed, k=1, metric='cos-sim', args=None, num_chunks=bs)\n",
    "    labels = torch.cat((torch.ones_like(scores_in), torch.zeros_like(scores_out)))\n",
    "    \n",
    "    auroc_real1 = roc_auc_score(labels.cpu(), torch.cat((scores_in, scores_out)).cpu()) * 100\n",
    "    auroc_adv1 = roc_auc_score(labels.cpu(), torch.cat((scores_in, scores_adv)).cpu()) * 100\n",
    "    \n",
    "    mask = torch.ones(len(x_train_embed)).bool()\n",
    "    mask[train_idx] = False\n",
    "    x_train_embed = x_train_embed[mask]\n",
    "    \n",
    "    scores_in = OOD_classifier_knn(x_train_embed, x_embed, k=1, metric='cos-sim', args=None, num_chunks=bs)\n",
    "    scores_out = OOD_classifier_knn(x_train_embed, y_embed, k=1, metric='cos-sim', args=None, num_chunks=bs)\n",
    "    scores_adv = OOD_classifier_knn(x_train_embed, adv_embed, k=1, metric='cos-sim', args=None, num_chunks=bs)\n",
    "    labels = torch.cat((torch.ones_like(scores_in), torch.zeros_like(scores_out)))\n",
    "                        \n",
    "    auroc_real2 = roc_auc_score(labels.cpu(), torch.cat((scores_in, scores_out)).cpu()) * 100\n",
    "    auroc_adv2 = roc_auc_score(labels.cpu(), torch.cat((scores_in, scores_adv)).cpu()) * 100\n",
    "                        \n",
    "    return dict(\n",
    "        auroc_real=auroc_real1,\n",
    "        auroc_adv=auroc_adv1,\n",
    "        auroc_real_sub=auroc_real2,\n",
    "        auroc_adv_sub=auroc_adv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc519a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_auroc = eval_auroc(result_smooth, x_embed, train_idx)\n",
    "patchy_auroc = eval_auroc(result_patchy, x_embed, train_idx)\n",
    "smooth_auroc['smooth_lambda'] = smooth_lambda\n",
    "patchy_auroc['smooth_lambda'] = 0\n",
    "df = pd.DataFrame([smooth_auroc, patchy_auroc])\n",
    "df.to_csv(out_dir / 'results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1f94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
