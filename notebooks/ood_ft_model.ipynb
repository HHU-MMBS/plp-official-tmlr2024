{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to evaluate the finetuned models (`finetune.py`) on OOD benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/plp-official-tmlr2024/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from model_builders import load_backbone,get_embed_dim\n",
    "from loaders.datasets import get_ood, get_num_classes\n",
    "from finetune import get_args_parser,build_transform,get_head\n",
    "from eval import *\n",
    "from eval.utils import *\n",
    "import glob \n",
    "from eval_args import *\n",
    "\n",
    "# Provide you paths to the checkpoint of the `finetune.py` experiments\n",
    "# If you want to evauate just a single experiments pass the pth path to the `paths` as a list\n",
    "base_path=Path(\"base_exp_path\") # to eval all finetune experiments together\n",
    "paths = list(base_path.rglob(\"/*/checkpoint_teacher*.pth\"))\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "        print(path)\n",
    "        with open(path.parent / 'hp.json', 'r') as f:\n",
    "            hp = json.load(f)\n",
    "        args = get_args_parser().parse_args(\"\")\n",
    "        args.arch = hp['arch']\n",
    "        args.dataset = hp['dataset']\n",
    "        args.out_dist = get_ood(args.dataset)[0]\n",
    "        args.head=False\n",
    "        args.precomputed = False\n",
    "        args.train_backbone = True\n",
    "        args.batch_size = 64\n",
    "        \n",
    "        exp_params = {\n",
    "            'dataset': args.dataset,\n",
    "            'out_dist': args.out_dist,\n",
    "            'arch': args.arch,\n",
    "            'freeze_percent': hp['freeze_blocks']\n",
    "        }\n",
    "        \n",
    "        args.nb_classes = get_num_classes(args.dataset)\n",
    "\n",
    "        model_ckpt = torch.load(path)\n",
    "        model, _ = load_backbone(args.arch)\n",
    "        transform = build_transform(False, args)\n",
    "        embed_dim = get_embed_dim(args=None, model=model)\n",
    "        head = get_head(embed_dim, args.nb_classes, args.init_scale)\n",
    "        model = nn.Sequential(model, head) \n",
    "        msg = model.load_state_dict(model_ckpt[\"model_ema\"], strict=True) # \"model\" or \"model_ema\"\n",
    "\n",
    "        args_eval = get_eval_args_parser().parse_args(\"\")\n",
    "        args_eval.eval_ood_knn = True\n",
    "        args_eval.eval_ood_maha = True\n",
    "        args_eval.eval_ood_norm = True\n",
    "        args_eval.eval_ood_logits = True\n",
    "        args_eval.dataset, args_eval.out_dist = args.dataset, args.out_dist\n",
    "        \n",
    "        dict1 = vars(args)\n",
    "        merged_dict = {**dict1}\n",
    "        merged_namespace = argparse.Namespace(**merged_dict)\n",
    "        args = merged_namespace\n",
    "        model.cuda()\n",
    "        epoch = model_ckpt[\"epoch\"]\n",
    "\n",
    "        extractor = FeatureExtractionPipeline(args, cache_backbone=False, model=model, transform=transform)\n",
    "        train_features, test_features, train_labels, test_labels_indist = extractor.get_train_logits(return_feats=True)\n",
    "        \n",
    "        ood_dl = extractor.get_dataloader(args.out_dist, train=False)\n",
    "        test_features_ood, ood_labels = extractor.get_logits(ood_dl)\n",
    "        \n",
    "        res_dict_ood_ckpt = eval_ood(args_eval, epoch, test_features, test_features_ood, train_features, train_labels)\n",
    "        res = flatten_result(res_dict_ood_ckpt)\n",
    "        res.update(exp_params)\n",
    "        results.append(res)\n",
    "        #model.cpu()\n",
    "        train_features, test_features, test_features_ood = None, None, None\n",
    "        torch.cuda.empty_cache()\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(base_path / f\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
